#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„æ‰¹é‡Googleå¹¿å‘ŠæŸ¥è¯¢è„šæœ¬
ä½¿ç”¨ç¼“å­˜æœºåˆ¶ï¼Œç”Ÿæˆå¾…æŸ¥è¯¢åˆ—è¡¨ä¾›Claude Code MCP Playwrightå·¥å…·ä½¿ç”¨
"""

import pandas as pd
import json
from datetime import datetime
from pathlib import Path

# ç¼“å­˜æ–‡ä»¶
CACHE_FILE = 'ads_cache.json'

class AdsCache:
    def __init__(self, cache_file=CACHE_FILE):
        self.cache_file = cache_file
        self.cache = self._load_cache()

    def _load_cache(self):
        if Path(self.cache_file).exists():
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def _save_cache(self):
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)

    def get(self, domain):
        return self.cache.get(domain)

    def set(self, domain, has_ads, ad_count, ad_count_text):
        self.cache[domain] = {
            'domain': domain,
            'has_ads': has_ads,
            'ad_count': ad_count,
            'ad_count_text': ad_count_text,
            'timestamp': datetime.now().isoformat()
        }
        self._save_cache()

    def is_fresh(self, domain, max_age_days=30):
        if domain not in self.cache:
            return False
        cached_time = datetime.fromisoformat(self.cache[domain]['timestamp'])
        age = (datetime.now() - cached_time).days
        return age < max_age_days

    def get_all(self):
        return self.cache


def parse_ad_count_text(text):
    """ä»å¹¿å‘Šæ•°é‡æ–‡æœ¬ä¸­è§£æå‡ºæ•°å­—"""
    if not text or '0 ä¸ªå¹¿å‘Š' in text or 'æœªæ‰¾åˆ°' in text:
        return False, 0

    try:
        if '~' in text:
            # ~200 ä¸ªå¹¿å‘Š
            num = int(text.split('~')[1].split(' ')[0])
            return True, num
        elif text[0].isdigit():
            # 42 ä¸ªå¹¿å‘Š
            num = int(text.split(' ')[0])
            return True, num
    except:
        pass

    return False, 0


def main():
    print("="*100)
    print("ğŸ“Š æ‰¹é‡Googleå¹¿å‘ŠæŸ¥è¯¢å·¥å…·ï¼ˆå¸¦ç¼“å­˜ï¼‰")
    print("="*100)

    # è¯»å–æ•°æ®
    df = pd.read_csv('hangzhou_stores_20k_200k.csv')

    # åˆå§‹åŒ–ç¼“å­˜
    cache = AdsCache()

    # å‡†å¤‡æ•°æ®
    all_domains = []
    cached_domains = []
    to_check_domains = []

    print(f"\nğŸ“¦ æ£€æŸ¥ç¼“å­˜çŠ¶æ€...\n")

    for _, row in df.iterrows():
        domain = row['domain'].replace('www.', '')
        merchant_name = row['merchant_name']
        monthly_visits = row['estimated_monthly_visits']

        domain_info = {
            'domain': domain,
            'merchant_name': merchant_name,
            'monthly_visits': monthly_visits,
            'url': f"https://adstransparency.google.com/?region=anywhere&domain={domain}"
        }

        all_domains.append(domain_info)

        if cache.is_fresh(domain):
            cached_data = cache.get(domain)
            domain_info.update(cached_data)
            cached_domains.append(domain_info)
            status = 'âœ…' if cached_data.get('has_ads') else 'â­•'
            print(f"  {status} ç¼“å­˜å‘½ä¸­: {domain} - {cached_data.get('ad_count_text', 'æœªçŸ¥')}")
        else:
            to_check_domains.append(domain_info)

    # ç»Ÿè®¡
    print(f"\n{'='*100}")
    print(f"ğŸ“Š ç»Ÿè®¡ï¼š")
    print(f"  æ€»åŸŸåæ•°: {len(all_domains)}")
    print(f"  å·²ç¼“å­˜: {len(cached_domains)} ä¸ª")
    print(f"  éœ€è¦æŸ¥è¯¢: {len(to_check_domains)} ä¸ª")
    print(f"{'='*100}\n")

    # å¦‚æœå…¨éƒ¨å·²ç¼“å­˜
    if not to_check_domains:
        print("âœ… å…¨éƒ¨åŸŸåå·²ç¼“å­˜ï¼\n")
        generate_report(cached_domains)
        return

    # ç”Ÿæˆå¾…æŸ¥è¯¢åˆ—è¡¨
    print(f"{'='*100}")
    print(f"ğŸ” å¾…æŸ¥è¯¢åŸŸååˆ—è¡¨ ({len(to_check_domains)}ä¸ª)ï¼š")
    print(f"{'='*100}\n")

    # ç”Ÿæˆä¸€ä¸ªæŸ¥è¯¢å‘½ä»¤åˆ—è¡¨æ–‡ä»¶
    commands = []

    for idx, item in enumerate(to_check_domains, 1):
        print(f"{idx}. {item['merchant_name']} ({item['domain']})")
        print(f"   æœˆè®¿é—®é‡: {item['monthly_visits']:,.0f}")
        print(f"   URL: {item['url']}")
        print()

        commands.append({
            'index': idx,
            'domain': item['domain'],
            'merchant_name': item['merchant_name'],
            'url': item['url']
        })

    # ä¿å­˜ä¸ºJSONæ–¹ä¾¿åç»­ä½¿ç”¨
    with open('domains_to_check.json', 'w', encoding='utf-8') as f:
        json.dump(commands, f, ensure_ascii=False, indent=2)

    print(f"{'='*100}")
    print(f"âœ… å¾…æŸ¥è¯¢åˆ—è¡¨å·²ä¿å­˜åˆ°: domains_to_check.json")
    print(f"{'='*100}\n")

    # æä¾›ä½¿ç”¨è¯´æ˜
    print("ğŸ“ ä½¿ç”¨è¯´æ˜ï¼š")
    print("="*100)
    print("1. ä½¿ç”¨Claude Codeçš„MCP Playwrightå·¥å…·é€ä¸ªè®¿é—®ä¸Šè¿°URL")
    print("2. åœ¨é¡µé¢ä¸­æŸ¥æ‰¾å¹¿å‘Šæ•°é‡ï¼ˆå¦‚ '~200 ä¸ªå¹¿å‘Š' æˆ– '0 ä¸ªå¹¿å‘Š'ï¼‰")
    print("3. å°†ç»“æœä¿å­˜åˆ°ç¼“å­˜ï¼š")
    print("   python3 -c \"")
    print("from batch_ads_checker_optimized import AdsCache")
    print("cache = AdsCache()")
    print("cache.set('domain.com', True, 200, '~200 ä¸ªå¹¿å‘Š')  # æœ‰å¹¿å‘Š")
    print("cache.set('domain.com', False, 0, '0 ä¸ªå¹¿å‘Š')      # æ— å¹¿å‘Š")
    print("\"")
    print("4. é‡æ–°è¿è¡Œæ­¤è„šæœ¬æŸ¥çœ‹æ›´æ–°åçš„ç»“æœ")
    print("="*100)

    # å¦‚æœæœ‰å·²ç¼“å­˜çš„æ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡
    if cached_domains:
        print(f"\n\n{'='*100}")
        print(f"ğŸ“Š å·²ç¼“å­˜çš„{len(cached_domains)}ä¸ªåŸŸåç»Ÿè®¡ï¼š")
        print(f"{'='*100}\n")
        generate_report(cached_domains)


def generate_report(domains):
    """ç”ŸæˆæŠ¥å‘Š"""
    # ç»Ÿè®¡
    has_ads_count = sum(1 for d in domains if d.get('has_ads', False))
    no_ads_count = len(domains) - has_ads_count
    total_ads = sum(d.get('ad_count', 0) for d in domains)

    print(f"ç»Ÿè®¡ç»“æœï¼š")
    print(f"  âœ… æœ‰å¹¿å‘Š: {has_ads_count} ä¸ª")
    print(f"  â­• æ— å¹¿å‘Š: {no_ads_count} ä¸ª")
    print(f"  ğŸ“Š å¹¿å‘Šæ€»æ•°: {total_ads} ä¸ª\n")

    # æŒ‰å¹¿å‘Šæ•°é‡æ’åº
    sorted_domains = sorted(domains, key=lambda x: x.get('ad_count', 0), reverse=True)

    print("è¯¦ç»†åˆ—è¡¨ï¼ˆæŒ‰å¹¿å‘Šæ•°é‡æ’åºï¼‰ï¼š")
    print("-"*100)
    for d in sorted_domains:
        status = 'âœ…' if d.get('has_ads') else 'â­•'
        ad_text = d.get('ad_count_text', 'æœªçŸ¥')
        print(f"{status} {d['merchant_name']:30} ({d['domain']:30}) - {ad_text}")

    # ä¿å­˜ç»“æœ
    df_results = pd.DataFrame(sorted_domains)
    df_results.to_csv('ads_check_results_cached.csv', index=False, encoding='utf-8-sig')
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: ads_check_results_cached.csv\n")


if __name__ == '__main__':
    main()
